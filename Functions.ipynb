{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59870eb-d2d2-414d-8997-9509a54c9c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computer Vision\n",
    "import cv2\n",
    "from cv2 import IMREAD_COLOR, IMREAD_UNCHANGED\n",
    "\n",
    "# Data Analysis and Visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Image Processing\n",
    "from scipy.ndimage import variance\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import laplace\n",
    "from skimage.transform import resize\n",
    "%matplotlib inline\n",
    "\n",
    "# File and Directory Handling\n",
    "import os\n",
    "from pathlib import Path, PureWindowsPath, WindowsPath\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "# Image Processing\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Utility Functions\n",
    "import platform\n",
    "import random\n",
    "import struct\n",
    "from functools import lru_cache\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from io import StringIO\n",
    "import glob\n",
    "import re\n",
    "import torch\n",
    "from scipy import linalg as la\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Miscellaneous\n",
    "import nbimporter\n",
    "import import_ipynb\n",
    "import splitfolders\n",
    "import pywt\n",
    "import sporco\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import platform\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "import hashlib\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4145dae0-ea3f-4026-af35-6d814a179fce",
   "metadata": {},
   "source": [
    "# Useful\n",
    "- https://github.com/Utkarsh-Deshmukh/Spatially-Varying-Blur-Detection-python\n",
    "- https://github.com/WillBrennan/BlurDetection2\n",
    "- https://tobiassunderdiek.github.io/cartoon-gan/\n",
    "- https://medium.com/geekculture/eda-for-image-classification-dcada9f2567a\n",
    "- https://datascience.stackexchange.com/questions/29223/exploratory-data-analysis-with-image-datset\n",
    "- https://www.youtube.com/watch?v=GIVK0-SNUgU\n",
    "- https://github.com/myazdani/pyImagePlot/tree/master/PyImagePlot\n",
    "- https://github.com/myazdani/data-analysis-for-ml\n",
    "- https://github.com/1solation/ham10000_exploratory_data_analysis\n",
    "- https://github.com/Recycleye/viz_eda\n",
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "raw",
   "id": "b28cb3f7-cba2-41a8-ba70-33d5380ef978",
   "metadata": {},
   "source": [
    "usePath = os.path.join(r'c:', os.sep,'Users','scrwh','Documents','PythonScripts')\n",
    "use = PureWindowsPath(usePath)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(use))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d688c-a2cc-47aa-b28e-5953ef5b12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_path_to_sys(path):\n",
    "#     usePath = os.path.join(path)\n",
    "#     use = PureWindowsPath(usePath)\n",
    "\n",
    "#     module_path = os.path.abspath(os.path.join(use))\n",
    "#     if module_path not in sys.path:\n",
    "#         sys.path.append(module_path)\n",
    "\n",
    "def add_path_to_sys(path):\n",
    "    module_path = os.path.abspath(path)\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc5e953-f69f-4761-bb83-47b487be1f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "usePath = os.path.join(r'c:', os.sep,'Users','scrwh','Documents','PythonScripts')\n",
    "add_path_to_sys(usePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050c115f-8812-45b8-9df1-13ba5448028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Master_Thesis.Function import ModelsListDiffFuntions\n",
    "print(dir(ModelsListDiffFuntions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3838c1e5-c22c-4e92-9a38-5940c3945085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FolderTree(FolderPath):\n",
    "    for root, dirs, files in os.walk(FolderPath):\n",
    "        level = root.count(os.sep) - FolderPath.count(os.sep)\n",
    "        indent = ' ' * 4 * level\n",
    "        num_files = len(files)\n",
    "        print(f\"{indent}{os.path.basename(root)}/ ({num_files} file{'s' if num_files != 1 else ''})\")\n",
    "        \n",
    "def get_file_list(data_folder):\n",
    "    return [os.path.join(dirpath, file) for dirpath, dirnames, files in os.walk(data_folder) for file in files]\n",
    "\n",
    "def get_file_list_imgs(data_folder):\n",
    "    return [os.path.join(dirpath, file) for dirpath, dirnames, files in os.walk(data_folder) for file in files if os.path.splitext(file)[1].lower() in ('.jpg', '.jpeg', '.png', '.bmp', '.gif')]\n",
    "\n",
    "import random\n",
    "\n",
    "def random_sample(items, sample_size, seed = 1234):\n",
    "    \"\"\"\n",
    "    Returns a random sample of size sample_size from items, using the seed specified.\n",
    "    \n",
    "    Parameters:\n",
    "    items (list): the list of items to sample from\n",
    "    sample_size (int): the number of items to sample\n",
    "    seed (int): the seed to use for the random number generator\n",
    "    \n",
    "    Returns:\n",
    "    list: a random sample of size sample_size from items\n",
    "    \"\"\"\n",
    "    # Set the seed for the random number generator\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Sample the items\n",
    "    return random.sample(items, sample_size)\n",
    "\n",
    "\n",
    "def get_image_paths(image_path):\n",
    "    if isinstance(image_path, list):\n",
    "        image_pathss = image_path\n",
    "    elif os.path.isdir(image_path):\n",
    "        image_pathss = [os.path.join(root, file)\n",
    "                       for root, dirs, files in os.walk(image_path)\n",
    "                       for file in files\n",
    "                       if file.endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    else:\n",
    "        image_pathss = [image_path]\n",
    "    return image_pathss\n",
    "\n",
    "def copy_and_open(images, output_dir):\n",
    "    output_dir = os.path.abspath(output_dir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for img_path in images:\n",
    "        img_path = os.path.abspath(img_path)\n",
    "        img_name = os.path.basename(img_path)\n",
    "        dest_path = os.path.join(output_dir, img_name)\n",
    "        shutil.copy(img_path, dest_path)\n",
    "    os.startfile(output_dir)\n",
    "    \n",
    "def sep():\n",
    "    return os.path.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e663bd-1f78-45e4-8111-24082d845e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "\n",
    "graphics = {\n",
    "    \"InputLayer\": \"  |  \",\n",
    "    \"Convolution1D\": \" \\|/ \",\n",
    "    \"Convolution2D\": \" \\|/ \",\n",
    "    \"Convolution3D\": \" \\|/ \",\n",
    "    \"Conv1D\": \" \\|/ \",\n",
    "    \"Conv2D\": \" \\|/ \",\n",
    "    \"Conv3D\": \" \\|/ \",\n",
    "    \"Conv2DTranspose\": \" /|\\ \",\n",
    "    \"SeparableConv2D\": r\" /|\\x\",\n",
    "    \"UpSampling1D\": \"AAAAA\",\n",
    "    \"UpSampling2D\": \"AAAAA\",\n",
    "    \"UpSampling3D\": \"AAAAA\",\n",
    "    \"Cropping1D\": \" ||| \",\n",
    "    \"Cropping2D\": \" ||| \",\n",
    "    \"Cropping2D\": \" ||| \",\n",
    "    \"Activation\": \" f| \",\n",
    "    \"Flatten\": \"|||||\",\n",
    "    \"MaxPooling1D\": \"Y max\",\n",
    "    \"MaxPooling2D\": \"Y max\",\n",
    "    \"MaxPooling3D\": \"Y max\",\n",
    "    \"AveragePooling1D\": \"Y avg\",\n",
    "    \"AveragePooling2D\": \"Y avg\",\n",
    "    \"AveragePooling3D\": \"Y avg\",\n",
    "    \"GlobalMaxPooling1D\": \"Y^max\",\n",
    "    \"GlobalMaxPooling2D\": \"Y^max\",\n",
    "    \"GlobalAveragePooling1D\": \"Y^avg\",\n",
    "    \"GlobalAveragePooling2D\": \"Y^avg\",\n",
    "    \"Dropout\": \" | ||\",\n",
    "    \"Dense\": \"XXXXX\",\n",
    "    \"ZeroPadding1D\": \"\\|||/\",\n",
    "    \"ZeroPadding2D\": \"\\|||/\",\n",
    "    \"ZeroPadding3D\": \"\\|||/\",\n",
    "    \"BatchNormalization\": \" μ|σ \",\n",
    "    \"Reshape\": \"  |  \",\n",
    "    \"Permute\": \"  |  \",\n",
    "    \"Embedding\": \"emb |\",\n",
    "    \"LSTM\": \"LLLLL\",\n",
    "    \"GRU\": \"LLLLL\"\n",
    "}\n",
    "\n",
    "def jsonize(model):\n",
    "    res = []\n",
    "    for layer in model.layers:\n",
    "        x = {}\n",
    "\n",
    "        x[\"name\"] = layer.name\n",
    "        x[\"kind\"] = layer.__class__.__name__\n",
    "        x[\"input_shape\"] = layer.input_shape[1:]\n",
    "        x[\"output_shape\"] = layer.output_shape[1:]\n",
    "        x[\"n_parameters\"] =  layer.count_params()\n",
    "        try:\n",
    "            x[\"activation\"] = layer.activation.__name__\n",
    "        except AttributeError:\n",
    "            x[\"activation\"] = \"\"\n",
    "\n",
    "        res.append(x)\n",
    "    return res\n",
    "\n",
    "def compress_layers(jsonized_layers):\n",
    "    res = [jsonized_layers[0]]\n",
    "    for each in jsonized_layers[1:]:\n",
    "        if each[\"kind\"] == \"Activation\" and res[-1][\"activation\"] in [\"\", \"linear\"]:\n",
    "            res[-1][\"activation\"] = each[\"activation\"]\n",
    "        else:\n",
    "            res.append(each)\n",
    "    return res\n",
    "\n",
    "# data_template = \"{activation:>15s}   #####   {shape} = {length}\"\n",
    "data_template = \"{activation:>20s}   #####   {shape}\"\n",
    "layer_template = \"{kind:>20s}   {graphics} -------------------{n_parameters:10d}   {percent_parameters:5.1f}%\"\n",
    "\n",
    "def product(iterable):\n",
    "    res = 1\n",
    "    for each in iterable:\n",
    "        res *= each\n",
    "    return res\n",
    "\n",
    "def print_dim_tuple(t):\n",
    "    if len(t) > 1:\n",
    "        return \" \".join([\"{:4d}\".format(x) for x in t])\n",
    "    else:\n",
    "        return  \"{:9d}\".format(t[0])\n",
    "\n",
    "def print_layers(jsonized_layers, sparser=False, simplify=False, header=True):\n",
    "\n",
    "    if simplify:\n",
    "        jsonized_layers = compress_layers(jsonized_layers)\n",
    "\n",
    "    all_weights = sum([each[\"n_parameters\"] for each in jsonized_layers])\n",
    "\n",
    "    if header:\n",
    "        print(\"           OPERATION           DATA DIMENSIONS   WEIGHTS(N)   WEIGHTS(%)\\n\")\n",
    "\n",
    "    print(data_template.format(\n",
    "            activation=\"Input\",\n",
    "            shape=print_dim_tuple(jsonized_layers[0][\"input_shape\"]),\n",
    "            # length=product(jsonized_layers[0][\"output_shape\"])\n",
    "    ))\n",
    "\n",
    "    for each in jsonized_layers:\n",
    "\n",
    "        if sparser:\n",
    "            print(\"\")\n",
    "\n",
    "        print(layer_template.format(\n",
    "                kind=each[\"kind\"] if each[\"kind\"] != \"Activation\" else \"\",\n",
    "                graphics=graphics.get(each[\"kind\"], \"?????\"),\n",
    "                n_parameters=each[\"n_parameters\"],\n",
    "                percent_parameters=100 * each[\"n_parameters\"] / all_weights\n",
    "        ))\n",
    "\n",
    "        if sparser:\n",
    "            print(\"\")\n",
    "\n",
    "        print(data_template.format(\n",
    "                activation=each[\"activation\"] if each[\"activation\"] != \"linear\" else \"\",\n",
    "                shape=print_dim_tuple(each[\"output_shape\"]),\n",
    "                # length=product(each[\"output_shape\"])\n",
    "        ))\n",
    "\n",
    "def sequential_model_to_ascii_printout(model, sparser=False, simplify=True, header=True):\n",
    "    print_layers(jsonize(model), sparser=sparser, simplify=simplify, header=header)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b4ede5e-34e1-4c24-82d4-3f320f25a6fb",
   "metadata": {},
   "source": [
    "def sequential_model_to_ascii_printout(model, sparser=True, simplify=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab0760b0-17ef-4ed2-80af-185db8b06fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def loadImages(path):\n",
    "    '''Put files into lists and return them as one list with all images \n",
    "     in the folder'''\n",
    "    image_files = sorted([os.path.join(path, 'train', file)\n",
    "                          for file in os.listdir(path + \"/train\")\n",
    "                          if file.endswith((\".jpg\", \".jpeg\", \".png\"))])\n",
    "    return image_files\n",
    "\n",
    "# Display two images\n",
    "def display(a, b, title1 = \"Original\", title2 = \"Edited\"):\n",
    "    plt.subplot(121), plt.imshow(a), plt.title(title1)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122), plt.imshow(b), plt.title(title2)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "# Display one image\n",
    "def display_one(a, title1 = \"Original\"):\n",
    "    plt.imshow(a), plt.title(title1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "def processing(data, height = 220, width = 220):\n",
    "    \n",
    "    # Reading 3 images to work\n",
    "    img = [cv2.imread(i, cv2.IMREAD_UNCHANGED) for i in data[:3]]\n",
    "    try:\n",
    "        print('Original size',img[0].shape)\n",
    "    except AttributeError:\n",
    "        print(\"shape not found\")\n",
    "   \n",
    "    # --------------------------------\n",
    "    # setting dim of the resize\n",
    "    # height = 220\n",
    "    # width = 220\n",
    "    dim = (width, height)\n",
    "    res_img = []\n",
    "    for i in range(len(img)):\n",
    "        res = cv2.resize(img[i], dim, interpolation=cv2.INTER_LINEAR)\n",
    "        res_img.append(res)\n",
    "\n",
    "    # Checcking the size\n",
    "    try:\n",
    "        print('RESIZED', res_img[1].shape)\n",
    "    except AttributeError:\n",
    "        print(\"shape not found\")\n",
    "    \n",
    "    \n",
    "    # Visualizing one of the images in the array\n",
    "    original = res_img[1]\n",
    "    display_one(original)\n",
    "    # ----------------------------------\n",
    "    # Remove noise\n",
    "    # Using Gaussian Blur\n",
    "    no_noise = []\n",
    "    for i in range(len(res_img)):\n",
    "        blur = cv2.GaussianBlur(res_img[i], (5, 5), 0)\n",
    "        no_noise.append(blur)\n",
    "\n",
    "\n",
    "    image = no_noise[1]\n",
    "    display(original, image, 'Original', 'Blured')\n",
    "    #---------------------------------\n",
    "    # Segmentation\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Displaying segmented images\n",
    "    display(original, thresh, 'Original', 'Segmented')\n",
    "    # Further noise removal (Morphology)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    # sure background area\n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
    "\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
    "\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    #Displaying segmented back ground\n",
    "    display(original, sure_bg, 'Original', 'Segmented Background')\n",
    "\n",
    "    # Marker labelling\n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers + 1\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    markers = cv2.watershed(image, markers)\n",
    "    image[markers == -1] = [255, 0, 0]\n",
    "\n",
    "    # Displaying markers on the image\n",
    "    display(original, markers, 'Original', 'Marked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb4f52-efe9-413d-b1c5-ec4f9ee95435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
