{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd67214-33d9-4115-83e8-66e4671ee255",
   "metadata": {},
   "source": [
    "# Read Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f90727a2-cff8-4b3b-bfce-1a09e6874f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the images to be processed into a list\n",
    "def get_file_list(data_folder):\n",
    "    # Walk through the directory structure and collect all files\n",
    "    # Join the directory path and file name to create the complete file path\n",
    "    return [os.path.join(dirpath, file) for dirpath, dirnames, files in os.walk(data_folder) for file in files]\n",
    "\n",
    "# Get file list for images only\n",
    "def get_file_list_imgs(data_folder):\n",
    "    # Walk through the directory structure and collect only image files with specific extensions\n",
    "    return [os.path.join(dirpath, file) for dirpath, dirnames, files in os.walk(data_folder) for file in files if os.path.splitext(file)[1].lower() in ('.jpg', '.jpeg', '.png', '.bmp', '.gif')]\n",
    "\n",
    "def get_image_paths(image_path):\n",
    "    if isinstance(image_path, list):\n",
    "        # If the input is already a list of image paths, use it as is\n",
    "        image_paths = image_path\n",
    "    elif os.path.isdir(image_path):\n",
    "        # If the input is a directory, collect all image files within it\n",
    "        image_paths = [os.path.join(root, file)\n",
    "                       for root, dirs, files in os.walk(image_path)\n",
    "                       for file in files\n",
    "                       if file.endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    else:\n",
    "        # If the input is a single image file, use it as is\n",
    "        image_paths = [image_path]\n",
    "\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01d9510-7870-4ef7-87c7-d957c677c3ae",
   "metadata": {},
   "source": [
    "## Check for Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "062b33cf-40a4-4f8e-aa13-64f24656efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def copy_and_open(images, output_dir):\n",
    "    output_dir = os.path.abspath(output_dir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for img_path in images:\n",
    "        img_path = os.path.abspath(img_path)\n",
    "        img_name = os.path.basename(img_path)\n",
    "        dest_path = os.path.join(output_dir, img_name)\n",
    "        shutil.copy(img_path, dest_path)\n",
    "    os.startfile(output_dir)\n",
    "\n",
    "\n",
    "def display_random_images(images, n,saveDir = 'smapleImages',seed = 1234):\n",
    "    \"\"\"\n",
    "    Select n random images from a list of image file paths or a directory,\n",
    "    and print their sizes as titles in a grid.\n",
    "    \"\"\"\n",
    "    # If images is a directory, get all image file paths in the directory\n",
    "    images = get_image_paths(images)\n",
    "\n",
    "    # Select n random images from the list\n",
    "    random.seed(seed)\n",
    "    images = random.sample(images, n)\n",
    "    copy_and_open(images, saveDir)\n",
    "    n_cols = 3 if len(images) < 4 else 4\n",
    "    n_rows = int(np.ceil(len(images) / n_cols))\n",
    "\n",
    "\n",
    "    # Display the images in a grid with their sizes as titles\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(15, 5))\n",
    "    if n_rows == 1:\n",
    "        axs = np.expand_dims(axs, axis=0)\n",
    "    elif n_cols == 1:\n",
    "        axs = np.expand_dims(axs, axis=1)\n",
    "    for i, img_path in enumerate(images):\n",
    "        img = Image.open(img_path)\n",
    "        axs[i // n_cols, i % n_cols].imshow(img)\n",
    "        axs[i // n_cols, i % n_cols].set_title(f\"{img.size[0]}x{img.size[1]}\")\n",
    "        axs[i // n_cols, i % n_cols].axis('off')\n",
    "    for ax in axs.flat[len(images):]:\n",
    "        ax.axis('off')\n",
    "    saveDirResults = os.path.join(saveDir,'results')\n",
    "    os.makedirs(saveDirResults, exist_ok=True)\n",
    "    figname = os.path.join(saveDir,'results','sample_imge_size.png')\n",
    "    plt.savefig(figname, bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()\n",
    "    \n",
    "def get_blurred_images(images, threshold=100):\n",
    "    \"\"\"\n",
    "    Given a directory or list of image file paths,\n",
    "    returns a list of blurred image file paths.\n",
    "    \"\"\"\n",
    "    # If images is a directory, get all image file paths in the directory \n",
    "    images = get_image_paths(images)  \n",
    "    blurred_images = []\n",
    "    blurred_count = 0\n",
    "    # Loop through the images and check if they are blurred\n",
    "    for img_path in images:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:  # Skip if image could not be read\n",
    "            continue\n",
    "        # Calculate the variance of Laplacian of the image\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        fm = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        # If the variance is below a threshold, consider the image blurred\n",
    "        if fm < threshold:\n",
    "            blurred_images.append(img_path)\n",
    "            blurred_count += 1\n",
    "    return blurred_images,blurred_count\n",
    "    \n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def remove_blur(input_dir, output_dir = 'deblurred', threshold=30, kernel_size=(5, 5), sharpening=True, allowed_extensions=None):\n",
    "    \"\"\"\n",
    "    Remove blur from images in the input directory and save them in the output directory.\n",
    "\n",
    "    Arguments:\n",
    "    input_dir -- Input directory containing the images to be deblurred\n",
    "    output_dir -- Output directory to save the deblurred images\n",
    "    threshold -- Threshold for detecting blur (default: 30)\n",
    "    kernel_size -- Kernel size for Gaussian blur (default: (5, 5))\n",
    "    sharpening -- Apply sharpening after deblurring (default: True)\n",
    "    allowed_extensions -- Set of allowed file extensions for deblurring (default: ['.jpg', '.jpeg', '.png'])\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the output directory if it does not exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # input_dir = get_image_paths(input_dir) #os.path.abspath(input_dir)#.replace(\"\\\\\", \"/\")\n",
    "    # output_dir = os.path.abspath(output_dir).replace(\"\\\\\", \"/\")\n",
    "\n",
    "    if allowed_extensions is None:\n",
    "        allowed_extensions = set(['.jpg', '.jpeg', '.png'])\n",
    "\n",
    "    images = get_image_paths(input_dir)\n",
    "    deblurred_images = []\n",
    "    \n",
    "    for entry in images:\n",
    "        image = cv2.imread(entry)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        fm = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "\n",
    "        if fm < threshold:\n",
    "            blurred = cv2.GaussianBlur(image, kernel_size, 0)\n",
    "            deblurred = cv2.addWeighted(image, 1.5, blurred, -0.5, 0)\n",
    "\n",
    "            if sharpening:\n",
    "                kernel = np.array([[-1, -1, -1],\n",
    "                                   [-1,  9, -1],\n",
    "                                   [-1, -1, -1]])\n",
    "                deblurred = cv2.filter2D(deblurred, -1, kernel)\n",
    "\n",
    "            # Save deblurred image in the corresponding subdirectory of the output directory\n",
    "            output_subdir = os.path.join(output_dir, os.path.dirname(entry))\n",
    "            os.makedirs(output_subdir, exist_ok=True)\n",
    "            output_file_path = os.path.join(output_subdir, os.path.basename(entry))\n",
    "\n",
    "            cv2.imwrite(output_file_path, deblurred)\n",
    "            deblurred_images.append(output_file_path)\n",
    "        else:\n",
    "            # If image is not blurred, copy it to the output directory with the same folder structure\n",
    "            output_subdir = os.path.join(output_dir, os.path.dirname(entry)[len(input_dir):])\n",
    "            os.makedirs(output_subdir, exist_ok=True)\n",
    "            output_file_path = os.path.join(output_subdir, os.path.basename(entry))\n",
    "            shutil.copy(entry.path, output_file_path)\n",
    "            \n",
    "    return deblurred_images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def resize_images(input_dir, output_dir, quality=95, new_width=244, allowed_extensions=None):\n",
    "    \"\"\"\n",
    "    Resize images in the input directory and save them in the output directory.\n",
    "\n",
    "    Arguments:\n",
    "    input_dir -- Input directory containing the images to be resized\n",
    "    output_dir -- Output directory to save the resized images\n",
    "    quality -- JPEG quality for saving the resized images (default: 95)\n",
    "    new_width -- Width in pixels for resizing the images (default: 244)\n",
    "    allowed_extensions -- Set of allowed file extensions for resizing (default: ['.jpg', '.jpeg', '.png'])\n",
    "    \"\"\"\n",
    "    input_dir = os.path.abspath(input_dir).replace(\"\\\\\", \"/\")\n",
    "    output_dir = os.path.abspath(output_dir).replace(\"\\\\\", \"/\")\n",
    "\n",
    "    # Create the output directory if it does not exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    if allowed_extensions is None:\n",
    "        allowed_extensions = set(['.jpg', '.jpeg', '.png'])\n",
    "\n",
    "    images = [entry for entry in os.scandir(input_dir) if entry.is_file() and entry.name.lower().endswith(tuple(allowed_extensions))]\n",
    "    with tqdm(total=len(images), desc=\"Resizing images\", unit=\"file\", leave=False) as pbar:\n",
    "        for entry in images:\n",
    "            output_file_path = os.path.join(output_dir, f\"{entry.name}\")\n",
    "\n",
    "            # Check if the file already exists in the output directory\n",
    "            if os.path.exists(output_file_path):\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            # Resize the image\n",
    "            img = Image.open(entry.path)\n",
    "            wpercent = (new_width / float(img.size[0]))\n",
    "            hsize = int((float(img.size[1]) * float(wpercent)))\n",
    "            resized_img = img.resize((new_width, hsize), resample=Image.Resampling.LANCZOS)\n",
    "\n",
    "            # Save the resized image in the corresponding subdirectory of the output directory\n",
    "            resized_img.save(output_file_path, quality=quality)\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Recursively call the function on subdirectories\n",
    "    for entry in os.scandir(input_dir):\n",
    "        if entry.is_dir():\n",
    "            sub_input_dir = os.path.join(input_dir, entry.name).replace(\"\\\\\", \"/\")\n",
    "            sub_output_dir = os.path.join(output_dir, entry.name).replace(\"\\\\\", \"/\")\n",
    "            resize_images(sub_input_dir, sub_output_dir, quality=quality, new_width=new_width, allowed_extensions=allowed_extensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab906c8-9a29-4cd4-850b-344495653849",
   "metadata": {},
   "source": [
    "# Image Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41fc7a18-6c26-44ba-ab54-f0864ee1a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import random\n",
    "import re\n",
    "import sporco\n",
    "import torch\n",
    "from scipy import linalg as la\n",
    "from torchvision.models.vgg import vgg19\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def signaltonoise(a, axis, ddof):\n",
    "    \"\"\"\n",
    "    Compute the signal-to-noise ratio of an array.\n",
    "\n",
    "    Args:\n",
    "        a (ndarray): Input array.\n",
    "        axis (int or None): Axis along which to compute the mean and standard deviation.\n",
    "        ddof (int): Delta degrees of freedom.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Signal-to-noise ratio.\n",
    "\n",
    "    \"\"\"\n",
    "    a = np.asanyarray(a)\n",
    "    m = a.mean(axis)\n",
    "    sd = a.std(axis=axis, ddof=ddof)\n",
    "    return np.where(sd == 0, 0, m / sd)\n",
    "\n",
    "\n",
    "def lowpass(s, lda, npad):\n",
    "    \"\"\"\n",
    "    Perform low pass filtering using Tikhonov filter.\n",
    "\n",
    "    Args:\n",
    "        s (ndarray): Input array.\n",
    "        lda (float): Regularization parameter.\n",
    "        npad (int): Number of pixels to pad.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Filtered array.\n",
    "\n",
    "    \"\"\"\n",
    "    # return tikhonov_filter(s, lda, npad)\n",
    "    return sporco.signal.tikhonov_filter(s, lda, npad)\n",
    "\n",
    "\n",
    "def get_activation(model, layer_numbers, input_image):\n",
    "    \"\"\"\n",
    "    Get the activations of specified layers in a given model.\n",
    "\n",
    "    Args:\n",
    "        model: Pretrained model.\n",
    "        layer_numbers (list): List of layer numbers to retrieve activations from.\n",
    "        input_image (Tensor): Input image.\n",
    "\n",
    "    Returns:\n",
    "        list: List of activation arrays.\n",
    "\n",
    "    \"\"\"\n",
    "    outs = []\n",
    "    out = input_image\n",
    "    for i in range(max(layer_numbers) + 1):\n",
    "        with torch.no_grad():  # Reduces memory usage and speeds up calculations\n",
    "            out = model.features[i](out)\n",
    "        if i in layer_numbers:\n",
    "            outs.append(np.rollaxis(out.detach().cpu().numpy()[0], 0, 3))\n",
    "    return outs\n",
    "\n",
    "\n",
    "def c3(s):\n",
    "    \"\"\"\n",
    "    Convert a 2D or 3D image to a 3D array and rotate.\n",
    "\n",
    "    Args:\n",
    "        s (ndarray): Input image.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Rotated 3D array.\n",
    "\n",
    "    \"\"\"\n",
    "    if s.ndim == 2:\n",
    "        s3 = np.dstack([s, s, s])\n",
    "    else:\n",
    "        s3 = s\n",
    "    return np.rollaxis(s3, 2, 0)[None, :, :, :]\n",
    "\n",
    "\n",
    "def l1_features(out):\n",
    "    \"\"\"\n",
    "    Compute L1 norm of the given array and return a matrix with zero edges.\n",
    "\n",
    "    Args:\n",
    "        out (ndarray): Input array.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: L1 norm array with zero edges.\n",
    "\n",
    "    \"\"\"\n",
    "    h, w, d = out.shape\n",
    "    a_temp = np.zeros((h + 2, w + 2))  # All edges of the Matrix have been zero\n",
    "\n",
    "    l1_norm = np.sum(np.abs(out), axis=2)\n",
    "    a_temp[1:h + 1, 1:w + 1] = l1_norm\n",
    "    return a_temp\n",
    "\n",
    "\n",
    "\n",
    "def Fusion_PCA(rgb, sar):\n",
    "    \"\"\"\n",
    "    Performs image fusion using PCA (Principal Component Analysis) algorithm.\n",
    "\n",
    "    Args:\n",
    "        rgb (numpy.ndarray): RGB image dataset (matrix) to be fused.\n",
    "        sar (numpy.ndarray): SAR image dataset (matrix) to be fused.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Fused image dataset (matrix).\n",
    "    \"\"\"\n",
    "    # Converting Image data to numpy Array to be able to do necessary calculation\n",
    "    a = np.array(rgb)\n",
    "    b = np.array(sar)\n",
    "    # getting Image dimensions\n",
    "    temp1 = a.shape\n",
    "    temp2 = b.shape\n",
    "    # Starting PCA algorithm\n",
    "    # creating matrix with both Images\n",
    "    vector1 = np.reshape(a, temp1[0] * temp1[1], order='F')\n",
    "    vector2 = np.reshape(b, temp2[0] * temp2[1], order='F')\n",
    "    # Convolution of created matrix\n",
    "    c = np.cov(vector1, vector2)\n",
    "    # getting Eigenvalue and Eigenvector of this matrix\n",
    "    d, v = la.eig(c)\n",
    "    sum1 = np.sum(v, axis=0)\n",
    "    # Calculating PCA\n",
    "    if d[0] >= d[1]:\n",
    "        pca = np.divide(v[:, 0], sum1[0])\n",
    "    else:\n",
    "        pca = np.divide(v[:, 1], sum1[1])\n",
    "    # Creating fused image\n",
    "    result = (pca[0] * rgb) + (pca[1] * sar)\n",
    "    return result\n",
    "\n",
    "\n",
    "def Fusion_DWT_db2(rgb, sar):\n",
    "    \"\"\"\n",
    "    Performs image fusion using Discrete Wavelet Transform (DWT) with Daubechies filter (db2).\n",
    "\n",
    "    Args:\n",
    "        rgb (numpy.ndarray): RGB image dataset (matrix) to be fused.\n",
    "        sar (numpy.ndarray): SAR image dataset (matrix) to be fused.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Fused image dataset (matrix).\n",
    "    \"\"\"\n",
    "    # decomposing each image using Discrete Wavelet Transform (DWT) with Daubechies filter (db2)\n",
    "    coefficients_1 = pywt.wavedec2(rgb, 'db2', level=2)\n",
    "    coefficients_2 = pywt.wavedec2(sar, 'db2', level=2)\n",
    "    # creating variables to be used\n",
    "    coefficients_h = list(coefficients_1)\n",
    "    # fusing the decomposed image data\n",
    "    coefficients_h[0] = (coefficients_1[0] + coefficients_2[0]) * 0.5\n",
    "    # creating variables to be used\n",
    "    temp1 = list(coefficients_1[1])\n",
    "    temp2 = list(coefficients_2[1])\n",
    "    temp3 = list(coefficients_h[1])\n",
    "    # fusing the decomposed image data\n",
    "    temp3[0] = (temp1[0] + temp2[0]) * 0.5\n",
    "    temp3[1] = (temp1[1] + temp2[1]) * 0.5\n",
    "    temp3[2] = (temp1[2] + temp2[2]) * 0.5\n",
    "    coefficients_h[1] = tuple(temp3)\n",
    "    # Creating fused image by reconstructing the fused decomposed image\n",
    "    result = pywt.waverec2(coefficients_h, 'db2')\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def fusion_strategy(feat_a, feat_b, source_a, source_b, img, unit):\n",
    "    \"\"\"\n",
    "    Weighted-averaging method for fusion of SAR and RGB images.\n",
    "    Args:\n",
    "        feat_a: Feature map of image A.\n",
    "        feat_b: Feature map of image B.\n",
    "        source_a: Source image A.\n",
    "        source_b: Source image B.\n",
    "        img: Image to be fused.\n",
    "        unit: Unit size for fusion.\n",
    "\n",
    "    Returns:\n",
    "        Fused image.\n",
    "    \"\"\"\n",
    "    m, n = feat_a.shape\n",
    "    m1, n1 = source_a.shape[:2]\n",
    "    weight_ave_temp1 = np.zeros((m1, n1))\n",
    "    weight_ave_temp2 = np.zeros((m1, n1))\n",
    "    weight_ave_temp3 = np.zeros((m1, n1))\n",
    "\n",
    "    for i in range(1, m):\n",
    "        for j in range(1, n):\n",
    "            a1 = feat_a[i - 1:i + 1, j - 1:j + 1].sum() / 9\n",
    "            a2 = feat_b[i - 1:i + 1, j - 1:j + 1].sum() / 9\n",
    "            a3 = img[i - 1:i + 1, j - 1:j + 1].sum() / 9\n",
    "\n",
    "            weight_ave_temp1[(i - 2) * unit + 1:(i - 1) * unit + 1, (j - 2) * unit + 1:(j - 1) * unit + 1] = a1 / (\n",
    "                a1 + a2 + a3)\n",
    "            weight_ave_temp2[(i - 2) * unit + 1:(i - 1) * unit + 1, (j - 2) * unit + 1:(j - 1) * unit + 1] = a2 / (\n",
    "                a1 + a2 + a3)\n",
    "            weight_ave_temp3[(i - 2) * unit + 1:(i - 1) * unit + 1, (j - 2) * unit + 1:(j - 1) * unit + 1] = a3 / (\n",
    "                a1 + a2 + a3)\n",
    "\n",
    "    if source_a.ndim == 3:\n",
    "        weight_ave_temp1 = weight_ave_temp1[:, :, None]\n",
    "    source_a_fuse = source_a * weight_ave_temp1\n",
    "    if source_b.ndim == 3:\n",
    "        weight_ave_temp2 = weight_ave_temp2[:, :, None]\n",
    "    source_b_fuse = source_b * weight_ave_temp2\n",
    "    if img.ndim == 3:\n",
    "        weight_ave_temp3 = weight_ave_temp3[:, :, None]\n",
    "    source_img_fuse = img * weight_ave_temp3\n",
    "\n",
    "    if source_a.ndim == 3 or source_b.ndim == 3 or img.ndim == 3:\n",
    "        gen = np.atleast_3d(source_a_fuse) + np.atleast_3d(source_b_fuse) + np.atleast_3d(source_img_fuse)\n",
    "    else:\n",
    "        gen = source_a_fuse + source_b_fuse + source_img_fuse\n",
    "\n",
    "    return gen\n",
    "\n",
    "\n",
    "def fusion_strategy2(feat_a, feat_b, source_a, source_b, img1, img2, unit):\n",
    "    \"\"\"\n",
    "    Fusion strategy 2 for fusion of SAR and RGB images.\n",
    "    Args:\n",
    "        feat_a: Feature map of image A.\n",
    "        feat_b: Feature map of image B.\n",
    "        source_a: Source image A.\n",
    "        source_b: Source image B.\n",
    "        img1: Image 1 to be fused.\n",
    "        img2: Image 2 to be fused.\n",
    "        unit: Unit size for fusion.\n",
    "\n",
    "    Returns:\n",
    "        Fused image.\n",
    "    \"\"\"\n",
    "    m, n = feat_a.shape\n",
    "    m1, n1 = source_a.shape[:2]\n",
    "    weight_ave_temp1 = np.zeros((m1, n1))\n",
    "    weight_ave_temp2 = np.zeros((m1, n1))\n",
    "    weight_ave_temp3 = np.zeros((m1, n1))\n",
    "    weight_ave_temp4 = np.zeros((m1, n1))\n",
    "\n",
    "    for i in range(1, m):\n",
    "        for j in range(1, n):\n",
    "            a1 = feat_a[i - 1:i + 1, j - 1:j + 1].sum() / 9\n",
    "            a2 = feat_b[i - 1:i + 1, j - 1:j + 1].sum() / 9\n",
    "            a3 = img1[i - 1:i + 1, j - 1:j + 1].sum() / 9\n",
    "            a4 = img2[i - 1:i + 1, j - 1:j + 1].sum() / 9\n",
    "\n",
    "            weight_ave_temp1[(i - 2) * unit + 1:(i - 1) * unit + 1, (j - 2) * unit + 1:(j - 1) * unit + 1] = a1 / (\n",
    "                a1 + a2 + a3 + a4)\n",
    "            weight_ave_temp2[(i - 2) * unit + 1:(i - 1) * unit + 1, (j - 2) * unit + 1:(j - 1) * unit + 1] = a2 / (\n",
    "                a1 + a2 + a3 + a4)\n",
    "            weight_ave_temp3[(i - 2) * unit + 1:(i - 1) * unit + 1, (j - 2) * unit + 1:(j - 1) * unit + 1] = a3 / (\n",
    "                a1 + a2 + a3 + a4)\n",
    "            weight_ave_temp4[(i - 2) * unit + 1:(i - 1) * unit + 1, (j - 2) * unit + 1:(j - 1) * unit + 1] = a4 / (\n",
    "                a1 + a2 + a3 + a4)\n",
    "\n",
    "    if source_a.ndim == 3:\n",
    "        weight_ave_temp1 = weight_ave_temp1[:, :, None]\n",
    "    source_a_fuse = source_a * weight_ave_temp1\n",
    "    if source_b.ndim == 3:\n",
    "        weight_ave_temp2 = weight_ave_temp2[:, :, None]\n",
    "    source_b_fuse = source_b * weight_ave_temp2\n",
    "    if img1.ndim == 3:\n",
    "        weight_ave_temp3 = weight_ave_temp3[:, :, None]\n",
    "    source_img_fuse = img1 * weight_ave_temp3\n",
    "    if img2.ndim == 3:\n",
    "        weight_ave_temp4 = weight_ave_temp4[:, :, None]\n",
    "    source_img2_fuse = img2 * weight_ave_temp4\n",
    "\n",
    "    if source_a.ndim == 3 or source_b.ndim == 3 or img1.ndim == 3 or img2.ndim == 3:\n",
    "        gen = np.atleast_3d(source_a_fuse) + np.atleast_3d(source_b_fuse) + np.atleast_3d(\n",
    "            source_img_fuse) + np.atleast_3d(source_img2_fuse)\n",
    "    else:\n",
    "        gen = source_a_fuse + source_b_fuse + source_img_fuse + source_img2_fuse\n",
    "\n",
    "    return gen\n",
    "\n",
    "\n",
    "def fuse(rgb, sar, model=None):\n",
    "    \"\"\"\n",
    "    Fuse SAR and RGB images using a fusion strategy.\n",
    "    Args:\n",
    "        rgb: RGB image.\n",
    "        sar: SAR image.\n",
    "        model: Pre-trained VGG19 model for feature extraction.\n",
    "\n",
    "    Returns:\n",
    "        Fused image.\n",
    "    \"\"\"\n",
    "    \n",
    "    rgb = cv2.imread(rgb)\n",
    "    sar = cv2.imread(sar)\n",
    "    \n",
    "    if len((sar).shape) != 2:\n",
    "        sar = cv.cvtColor(sar, cv.COLOR_BGR2GRAY)\n",
    "    if len((rgb).shape) != 2:\n",
    "        rgb = cv.cvtColor(rgb, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    npad = 16\n",
    "    lda = 5\n",
    "    rgb_low, rgb_high = lowpass(rgb.astype(np.float32) / 255, lda, npad)\n",
    "    sar_low, sar_high = lowpass(sar.astype(np.float32) / 255, lda, npad)\n",
    "\n",
    "    img = Fusion_DWT_db2(rgb.astype(np.float32) / 255, sar_high)\n",
    "    img1 = Fusion_PCA(sar.astype(np.float32) / 255, sar_high)\n",
    "    img2 = Fusion_PCA(rgb_high, rgb.astype(np.float32) / 255)\n",
    "    snr = np.max(signaltonoise(img, axis=0, ddof=0))\n",
    "\n",
    "    if model is None:\n",
    "        model = vgg19(True)\n",
    "    model.cuda().eval()\n",
    "    relus = [2, 7, 12, 21]\n",
    "    unit_relus = [1, 2, 4, 8]\n",
    "\n",
    "    rgb_in = torch.from_numpy(c3(rgb_high)).cuda()\n",
    "    sar_in = torch.from_numpy(c3(sar_high)).cuda()\n",
    "\n",
    "    relus_rgb = get_activation(model, relus, rgb_in)\n",
    "    relus_sar = get_activation(model, relus, sar_in)\n",
    "\n",
    "    rgb_feats = [l1_features(out) for out in relus_rgb]\n",
    "    sar_feats = [l1_features(out) for out in relus_sar]\n",
    "\n",
    "    saliencies = []\n",
    "    saliency_max = None\n",
    "\n",
    "    if 10 < snr < 19:\n",
    "        for idx in range(len(relus)):\n",
    "            saliency_current = fusion_strategy(rgb_feats[idx], sar_feats[idx],\n",
    "                                               rgb_high, sar_high, img, unit_relus[idx])\n",
    "            saliencies.append(saliency_current)\n",
    "\n",
    "            if saliency_max is None:\n",
    "                saliency_max = saliency_current\n",
    "            else:\n",
    "                saliency_max = np.maximum(saliency_max, saliency_current)\n",
    "\n",
    "    else:\n",
    "        for idx in range(len(relus)):\n",
    "            saliency_current = fusion_strategy2(rgb_feats[idx], sar_feats[idx],\n",
    "                                                rgb_high, sar_high, img1, img2, unit_relus[idx])\n",
    "            saliencies.append(saliency_current)\n",
    "\n",
    "            if saliency_max is None:\n",
    "                saliency_max = saliency_current\n",
    "            else:\n",
    "                saliency_max = np.maximum(saliency_max, saliency_current)\n",
    "\n",
    "    if rgb_low.ndim == 3 or sar_low.ndim == 3:\n",
    "        low_fused = np.atleast_3d(rgb_low) + np.atleast_3d(sar_low)\n",
    "    else:\n",
    "        low_fused = rgb_low + sar_low\n",
    "    low_fused = low_fused / 2\n",
    "    high_fused = saliency_max\n",
    "\n",
    "    return low_fused + high_fused\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def show_images(rgb_image, sar_image, fused_image):\n",
    "    \"\"\"\n",
    "    Display RGB, SAR, and fused images using matplotlib.pyplot.\n",
    "\n",
    "    Arguments:\n",
    "    rgb_image -- RGB image as a numpy array or a string representing the image file path\n",
    "    sar_image -- SAR image as a numpy array or a string representing the image file path\n",
    "    fused_image -- Fused image as a numpy array or a string representing the image file path\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the input images are numpy arrays or file paths\n",
    "    if isinstance(rgb_image, str):\n",
    "        rgb_image = cv2.imread(rgb_image)  # Read RGB image using cv2 if it is a file path\n",
    "    if isinstance(sar_image, str):\n",
    "        sar_image = cv2.imread(sar_image, cv2.IMREAD_GRAYSCALE)  # Read SAR image using cv2 if it is a file path\n",
    "    if isinstance(fused_image, str):\n",
    "        fused_image = cv2.imread(fused_image)  # Read fused image using cv2 if it is a file path\n",
    "\n",
    "    # Create a figure and set up subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "    # Plot RGB image\n",
    "    axes[0].imshow(rgb_image)\n",
    "    axes[0].set_title('RGB Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Plot SAR image\n",
    "    axes[1].imshow(sar_image)\n",
    "    axes[1].set_title('SAR Image')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Plot fused image\n",
    "    axes[2].imshow(fused_image, cmap='gray')\n",
    "    axes[2].set_title('Fused Image')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    # Adjust spacing between subplots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the figure\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6ae029-c525-4e96-bc37-de2770cdeabc",
   "metadata": {},
   "source": [
    "# Image data and Model implementation \n",
    "## Split Image data into Train, Validate, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b6751-e309-4774-89c7-bc66442fa2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import splitfolders\n",
    "\n",
    "# Define the output folder name\n",
    "output_folder = \"data3\"\n",
    "\n",
    "root = sys.path[0]\n",
    "\n",
    "# Create the full path for the output folder\n",
    "data_folder = os.path.join(root, output_folder)\n",
    "\n",
    "# Define the input folder path\n",
    "# /d/Jacobs/Semester4/Master_Thesis/Acquahmeyer/Sample_Dataset/Sar and RGB/archive/fused_image\n",
    "input_folder = os.path.join(\"D\", os.sep, \"Jacobs\", \"Semester4\", \"Master_Thesis\", \"Acquahmeyer\", \"Sample_Dataset\", \"Sar and RGB\", \"archive\", \"fused_image\")\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# Print the current working directory\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Directory:\", current_directory)\n",
    "\n",
    "# Split the input_folder into training, validation, and testing sets with a ratio of 70%, 20%, and 10% respectively\n",
    "splitfolders.ratio(\n",
    "    input_folder,\n",
    "    output=data_folder,\n",
    "    seed=1337,\n",
    "    ratio=(0.7, 0.2, 0.1),\n",
    "    group_prefix=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c46d16-ff42-4228-b248-ce88a4e9fd7a",
   "metadata": {},
   "source": [
    "## Build the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75799bcc-c2b0-4702-b4c0-6f6480176806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_generator(datagen, data_dir, subdir, img_size = 244, batch_size = 32):\n",
    "    if subdir != 'test':\n",
    "        shuffles=True\n",
    "    else:\n",
    "        shuffles=False\n",
    "    return datagen.flow_from_directory(\n",
    "        os.path.join(data_dir, subdir),\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle = shuffles\n",
    "        # class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "def custom_model(data_dir, batch_size=32, epochs=50, img_size=244, num_classes=9):\n",
    "    \n",
    "    # Build the model architecture\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional layers\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(img_size, img_size, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Flatten and dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "  \n",
    "def evaluate_models(data_dir, batch_size=32, epochs=50, img_size=244):\n",
    "    # Generate the folder path with the current date and time\n",
    "    foldername = os.path.join('Models', 'TrainingData').replace(os.path.sep, '/')\n",
    "    now = datetime.now().strftime('%Y-%m-%d %H%M')\n",
    "    folder_path = f'{foldername}_{now}'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # Check if a GPU is available\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        print(\"GPU available, training on GPU...\")\n",
    "        device_name = tf.test.gpu_device_name()\n",
    "    else:\n",
    "        print(\"GPU not available, training on CPU...\")\n",
    "        device_name = \"/CPU:0\"\n",
    "\n",
    "    # Data augmentation and generators\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "    # Data augmentation for the validation set\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Load the training, validation, and test sets\n",
    "    train_generator = load_data_generator(train_datagen, data_dir, 'train', img_size=img_size, batch_size=batch_size)\n",
    "    val_generator = load_data_generator(val_datagen, data_dir, 'val', img_size=img_size, batch_size=batch_size)\n",
    "    test_generator = load_data_generator(val_datagen, data_dir, 'test', img_size=img_size, batch_size=batch_size)\n",
    "\n",
    "    # Get the number of classes and labels\n",
    "    num_classes = len(train_generator.class_indices)\n",
    "    labels = list(train_generator.class_indices.keys())\n",
    "\n",
    "    # Model creation\n",
    "    models = [('Inception-V2', InceptionV3, 'imagenet'), ('ResNet-50', ResNet50, 'imagenet'),\n",
    "              ('ResNet-101', ResNet101, 'imagenet'), ('Inception-ResNet-V2', InceptionResNetV2, 'imagenet'),\n",
    "              ('VGG16', VGG16, 'imagenet'), ('Custom', custom_model, None)]\n",
    "\n",
    "    model_results = {'Model': [], 'Training Accuracy': [], 'Validation Accuracy': [], 'Test Accuracy': []}\n",
    "\n",
    "    for model_name, model_fn, weights in models:\n",
    "        if model_fn == custom_model:\n",
    "            model = model_fn(data_dir=data_dir, batch_size=batch_size, epochs=epochs, img_size=img_size, num_classes=num_classes)\n",
    "        else:\n",
    "            base_model = model_fn(input_shape=(img_size, img_size, 3), include_top=False, weights=weights)\n",
    "            x = Flatten()(base_model.output)\n",
    "            x = Dense(units=512, activation='relu')(x)\n",
    "            x = Dense(units=256, activation='relu')(x)\n",
    "            output = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "            model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "            for layer in base_model.layers:\n",
    "                layer.trainable = False\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Move the model to the GPU if available\n",
    "        with tf.device(device_name):\n",
    "            # Define the learning rate schedule\n",
    "            def lr_schedule(epoch):\n",
    "                learning_rate = 0.0001\n",
    "                if epoch > 30:\n",
    "                    learning_rate *= 0.1\n",
    "                elif epoch > 20:\n",
    "                    learning_rate *= 0.01\n",
    "                print('Learning rate:', learning_rate)\n",
    "                print(get_nvidia_gpu_memory())\n",
    "                return learning_rate\n",
    "\n",
    "            # Define the callbacks\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "            lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "            checkpoint = ModelCheckpoint(f'{folder_path}/best_{model_name}_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "            # Train the model\n",
    "            print(f'Training Model: {model_name}')\n",
    "            start_time = datetime.now()\n",
    "            print(f'{model_name} Started: {start_time}')\n",
    "            history = model.fit(\n",
    "                train_generator,\n",
    "                steps_per_epoch=len(train_generator),\n",
    "                epochs=epochs,\n",
    "                validation_data=val_generator,\n",
    "                validation_steps=len(val_generator),\n",
    "                callbacks=[early_stopping, reduce_lr, lr_scheduler, checkpoint]\n",
    "            )\n",
    "            end_time = datetime.now()\n",
    "            print(f'{model_name} Ended: {end_time}')\n",
    "            print(f'Duration: {end_time - start_time}')\n",
    "\n",
    "            # Run the garbage collector to free memory\n",
    "            gc.collect()\n",
    "\n",
    "            now = datetime.now().strftime('%Y-%m-%d %H%M')\n",
    "            # Save the model and its history to disk\n",
    "            model.save(f'{folder_path}/wind_turbine_{model_name}_model_{now}.h5')\n",
    "            with open(f'{folder_path}/wind_turbine_{model_name}_history_{now}.pkl', 'wb') as f:\n",
    "                pickle.dump(history.history, f)\n",
    "\n",
    "        # Evaluation\n",
    "        _, train_acc = model.evaluate(train_generator)\n",
    "        _, val_acc = model.evaluate(val_generator)\n",
    "        _, test_acc = model.evaluate(test_generator)\n",
    "        model_results['Model'].append(model_name)\n",
    "        model_results['Training Accuracy'].append(train_acc)\n",
    "        model_results['Validation Accuracy'].append(val_acc)\n",
    "        model_results['Test Accuracy'].append(test_acc)\n",
    "\n",
    "    # Saving the performance in a DataFrame\n",
    "    df = pd.DataFrame(model_results)\n",
    "    df.set_index('Model', inplace=True)\n",
    "    df['Average'] = df.select_dtypes(include='number').mean(axis=1)\n",
    "\n",
    "    # Generate the filename with the current date and time\n",
    "    file_name = os.path.join(folder_path, 'TrainingData').replace(os.path.sep, '/')\n",
    "    now = datetime.now().strftime('%Y-%m-%d %H%M')\n",
    "    filename = f'{file_name}_{now}.csv'\n",
    "\n",
    "    # Save the DataFrame to the CSV file\n",
    "    df.to_csv(filename, index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24363492-f09e-426e-a0ac-cbce77fb9fa6",
   "metadata": {},
   "source": [
    "## Model Results and Evaluation\n",
    "### Training History for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9199fa-2cf1-40f4-86b4-babe9ec056e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_histories(histories, model_names):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    metrics = ['accuracy', 'val_accuracy', 'loss', 'val_loss']\n",
    "    titles = ['Train Accuracy', 'Validation Accuracy', 'Train Loss', 'Validation Loss']\n",
    "    ylabels = ['Accuracy', 'Accuracy', 'Loss', 'Loss']\n",
    "    legends = model_names\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        axs[i].set_title(titles[i])\n",
    "        axs[i].set_ylabel(ylabels[i])\n",
    "        axs[i].set_xlabel('Epoch')\n",
    "\n",
    "        for j, history in enumerate(histories):\n",
    "            if 'history' in history:\n",
    "                history = history['history']\n",
    "            axs[i].plot(history[metric])\n",
    "\n",
    "        axs[i].margins(x=0)  # Remove horizontal margins to make full use of the plot\n",
    "\n",
    "        # Get the maximum number of epochs from all histories\n",
    "        max_epochs = max([len(history[metric]) for history in histories])\n",
    "\n",
    "        # Calculate the number of intervals on the x-axis\n",
    "        num_intervals = 5  # Adjust this value to control the number of intervals\n",
    "        interval = max_epochs // num_intervals\n",
    "\n",
    "        # Set the x-axis tick positions and labels\n",
    "        x_ticks = range(0, max_epochs + 1, interval)\n",
    "        x_labels = [str(x) for x in x_ticks]\n",
    "        axs[i].set_xticks(x_ticks)\n",
    "        axs[i].set_xticklabels(x_labels)\n",
    "\n",
    "        # Set the last epoch number as the x-axis label\n",
    "        # axs[i].set_xlabel('Epoch (Last: {})'.format(max_epochs))\n",
    "        \n",
    "        axs[i].set_xlabel('Epoch')\n",
    "\n",
    "    # Create a single legend outside the subplots with additional spacing and a title\n",
    "    fig.legend(legends, loc='upper right', bbox_to_anchor=(1.16, 0.95), title='Legend')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_histories.png', bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510c622a-dbc0-4821-91f4-a3c55111974d",
   "metadata": {},
   "source": [
    "## Evaluation results of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4008895-7f7f-4144-a623-1ae4caab7a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateTest(data_dir, model, history, batch_size=32, img_size=256):\n",
    "\n",
    "    # Data augmentation for test set\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)    \n",
    "    # load_data_generator(datagen, data_dir, subdir, img_size = 244, batch_size = 32)\n",
    "    test_generator = load_data_generator(test_datagen, data_dir, 'test', img_size = img_size, batch_size = batch_size)\n",
    "        \n",
    "    \n",
    "    # Create an empty dictionary to store time per image\n",
    "    time_per_image = {}\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    # print('\\n Evaluate the model on the test set')\n",
    "    start_time = time.time()\n",
    "    scores = model.evaluate(test_generator, steps=len(test_generator), verbose=1)\n",
    "    end_time = time.time()\n",
    "    # print(\"Test loss:\", scores[0])\n",
    "    # print(\"Test accuracy:\", scores[1])\n",
    "\n",
    "    # Calculate time per image in seconds\n",
    "    time_taken = end_time - start_time\n",
    "    time_per_image['test'] = time_taken / len(test_generator.filenames)\n",
    "\n",
    "    # Convert the dictionary to a pandas DataFrame\n",
    "    df = pd.DataFrame.from_dict(time_per_image, orient='index', columns=['Time per image (s)'])\n",
    "    print('EvaluateTime_report')\n",
    "    print(df)    \n",
    "    df.to_csv(\"EvaluateTime_report.csv\", index=True)\n",
    "    \n",
    "    \n",
    "    history = checkHistory(history)\n",
    "    \n",
    "    # get the index of the highest accuracy value\n",
    "    print('Training indexes')\n",
    "    highest_acc_index = np.argmax(history['val_accuracy'])\n",
    "    \n",
    "    # create a dictionary with the values\n",
    "    data = {'first': [history['loss'][0], history['accuracy'][0], \n",
    "                     history['val_loss'][0], history['val_accuracy'][0]],\n",
    "            'lowest': [min(history['loss']), min(history['accuracy']), \n",
    "                        min(history['val_loss']), min(history['val_accuracy'])],\n",
    "            'highest': [max(history['loss']), max(history['accuracy']), \n",
    "                        max(history['val_loss']), max(history['val_accuracy'])],\n",
    "            'last': [history['loss'][-1], history['accuracy'][-1], \n",
    "                     history['val_loss'][-1], history['val_accuracy'][-1]]\n",
    "           }\n",
    "    \n",
    "        # create a dataframe with the values as the index\n",
    "    df = pd.DataFrame(data, index=['training loss', 'training accuracy', 'validation loss', 'validation accuracy'])\n",
    "    # convert values to 4 decimal places\n",
    "    df = df.round(4)\n",
    "    df.to_csv('history.csv', index=True)\n",
    "    # print the dataframe\n",
    "    print(df,'\\n')\n",
    "\n",
    "    plot_training_history(history)\n",
    "\n",
    "    plot_training_historyB(history)\n",
    "    \n",
    "    classNmaes = list(test_generator.class_indices.keys())\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    print('\\n Evaluate the model on the test set')\n",
    "    print(\"Test loss:\", scores[0])\n",
    "    print(\"Test accuracy:\", scores[1])\n",
    "    \n",
    "    # Get the true labels and the predicted labels from the test set\n",
    "    true_labels = test_generator.classes\n",
    "    predicted_labels = model.predict(test_generator, steps=len(test_generator), verbose=1)\n",
    "\n",
    "    # Compute the binary true labels and predicted labels for each class\n",
    "    class_names = list(test_generator.class_indices.keys())\n",
    "    binary_true_labels = []\n",
    "    binary_predicted_labels = []\n",
    "    for i in range(len(class_names)):\n",
    "        class_idx = test_generator.class_indices[class_names[i]]\n",
    "        binary_true_labels.append((true_labels == class_idx).astype(int))\n",
    "        binary_predicted_labels.append(predicted_labels[:, i])\n",
    "\n",
    "    # Compute the ROC curve and AUC for each class\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    auc_roc_scores = []\n",
    "    for i in range(len(class_names)):\n",
    "        fpr, tpr, thresholds = roc_curve(binary_true_labels[i], binary_predicted_labels[i])\n",
    "        roc_auc = roc_auc_score(binary_true_labels[i], binary_predicted_labels[i])\n",
    "        auc_roc_scores.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=2, label=class_names[i] + ' (AUC = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=14)\n",
    "    plt.ylabel('True Positive Rate', fontsize=14)\n",
    "    plt.title('Receiver operating characteristic ROC', fontsize=16)\n",
    "    plt.legend(loc=\"lower right\")    \n",
    "    plt.savefig('auc_roc_scores.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(\"clases: \\n\", class_names)\n",
    "    # Compute the classification report    \n",
    "    predicted_labels = np.argmax(predicted_labels, axis=1)\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)    \n",
    "    \n",
    "    df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "    df_cm = df_cm.round(2)\n",
    "    df_cm.to_csv('confusion_matrix.csv', index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    cr = classification_report(true_labels, predicted_labels, target_names=class_names)\n",
    "    cr_dict = classification_report(true_labels, predicted_labels, target_names=class_names, output_dict=True)\n",
    "    df_cr = pd.DataFrame(cr_dict).transpose()\n",
    "    df_cr = df_cr.round(2)\n",
    "    df_cr.to_csv(\"classification_report.csv\", index=True)\n",
    "    \n",
    "    print(\" \\nConfusion matrix:\\n\", cm)\n",
    "    print(df_cm)\n",
    "    \n",
    "    \n",
    "    # plot_confusion_matrix(cm, class_names)\n",
    "    plot_confusion_matrixN(cm, class_names,normalize=True)\n",
    "    \n",
    "    sns.heatmap(df_cm, annot=True, cmap='Blues', fmt='g')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('Ground Truth label')    \n",
    "    name = \"Confusion_matrix_normalized.png\"\n",
    "    plt.savefig(name)\n",
    "    # plt.show()\n",
    "    \n",
    "    print(\" \\nClassification report:\\n\", cr)\n",
    "    print(df_cr)\n",
    "    \n",
    "\n",
    "    # Create a table of AUC-ROC scores for each class\n",
    "    auc_roc_table = pd.DataFrame({'Class': class_names, 'AUC-ROC': auc_roc_scores})\n",
    "    auc_roc_table = auc_roc_table.round(2)    \n",
    "    auc_roc_table.to_csv(\"auc_roc_table.csv\", index=False)\n",
    "    print(\"\\nauc_roc_table:\\n\", auc_roc_table)\n",
    "    \n",
    "    \n",
    "    lb = LabelBinarizer()\n",
    "    true_labels_binary = lb.fit_transform(true_labels)\n",
    "    predicted_labels_binary = lb.transform(predicted_labels)\n",
    "\n",
    "    avg_precision = average_precision_score(true_labels_binary, predicted_labels_binary, average='macro')\n",
    "    print(\"Average Precision Score: \", avg_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f9563-65f3-4cd9-9a61-3e638c7bbea7",
   "metadata": {},
   "source": [
    "## Detect Fault in sample or given set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ac2d5-00b1-4948-b398-908c2d6f1c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faultsdf(model, image_path, class_names, img_size=256, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Detects faults in a wind turbine blade image using a trained CNN model.\n",
    "\n",
    "    Args:\n",
    "    - model: Trained Keras model object\n",
    "    - image_path: File path of the input image or directory\n",
    "    - class_names: List of class names (in order of model output)\n",
    "\n",
    "    Returns:\n",
    "    - predictions: List of tuples representing the fault predictions\n",
    "        (fault_name, x1, y1, x2, y2, confidence)\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(image_path, list):\n",
    "        image_paths = image_path\n",
    "    elif os.path.isdir(image_path):\n",
    "        image_paths = [os.path.join(root, file)\n",
    "                       for root, dirs, files in os.walk(image_path)\n",
    "                       for file in files\n",
    "                       if file.endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    else:\n",
    "        image_paths = [image_path]\n",
    "\n",
    "    rows = 3 if len(image_paths) < 7 else 4\n",
    "    numm = math.ceil(len(image_paths) / rows)\n",
    "    # dim = (256, 256)\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    gs1 = gridspec.GridSpec(numm, rows)\n",
    "    gs1.update(wspace=0.025, hspace=0.08)\n",
    "\n",
    "    all_predictions = []\n",
    "    for idx, path in enumerate(image_paths):\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.resize(image, (img_size, img_size))\n",
    "        image = np.expand_dims(image, axis=0) / 255.\n",
    "\n",
    "        predictions = model.predict(image)\n",
    "        pred_labels = []\n",
    "        confidences = []        \n",
    "\n",
    "        colors = generate_colors(len(class_names))\n",
    "\n",
    "        ax1 = plt.subplot(gs1[idx])\n",
    "        ax1.imshow(np.squeeze(image))\n",
    "\n",
    "        for i, prediction in enumerate(predictions[0]):\n",
    "            if prediction >= threshold:\n",
    "                pred_labels.append(class_names[i])\n",
    "                confidences.append(prediction)\n",
    "                \n",
    "                x1, y1, x2, y2 = (10 * i, 10 * i, 200 - 10 * i, 200 - 10 * i)\n",
    "                colord = colors[i]\n",
    "                rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1,\n",
    "                                     fill=False, color=colord)\n",
    "                ax1.add_patch(rect)\n",
    "                ax1.text(x1, y1, f'{class_names[i]} ({prediction:.2f})',\n",
    "                         fontsize=14, fontweight='bold', color=colord)\n",
    "\n",
    "\n",
    "        gt_label = path.split(os.path.sep)[-2]\n",
    "        pred_label = ','.join(pred_labels) if pred_labels else 'None'\n",
    "        confidence = ','.join([f'{c:.2f}' for c in confidences]) if confidences else 'None'\n",
    "        \n",
    "        ax1.set_title(path.split(os.path.sep)[-2])\n",
    "        ax1.axis('off')\n",
    "\n",
    "        predictions = [(class_names[i], x1, y1, x2, y2, prediction)\n",
    "                       for i, prediction in enumerate(predictions[0])\n",
    "                       if prediction > 0.5]\n",
    "\n",
    "        all_predictions.append((os.path.basename(path), gt_label, pred_label, confidence))\n",
    "        # all_predictions.append(predictions)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    df = pd.DataFrame(all_predictions, columns=['Image', 'Ground Truth Label', 'Predicted Label', 'Confidence'])\n",
    "    \n",
    "    df_split = df.assign(Ground_Truth_Label=df['Ground Truth Label']).assign(Predicted_Label=df['Predicted Label'].str.split(',')).explode('Predicted_Label')\n",
    "\n",
    "    count = len(df_split[df_split['Ground_Truth_Label'] == df_split['Predicted_Label']])\n",
    "    countb = len(df_split[df_split['Ground_Truth_Label'] != df_split['Predicted_Label']])\n",
    "    print(f\"Total predictions that match each Ground Truth: {count}\")\n",
    "    print(f\"Total predictions that do not match each Ground Truth: {countb}\")\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
